{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ★ tensorflow ★\n",
    "그래프 형태의 수학식 계산을 수행하는 핵심 라이브러리를 구현한 후, 그 위에 여러 머신러닝을 쉽게 할 수 있는 다양한 라이브러리를 올린 형태\n",
    "\n",
    "**텐서플로 프로그램의 구조**\n",
    "\n",
    "1. 그래프 생성\n",
    "\n",
    "2. 그래프 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 텐서와 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서플로 사용을 위한 임포트\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#상수를 hello변수에 저장\n",
    "\n",
    "hello = tf.constant('Hello, Tensorflow!')\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ hello 변수가 텐서플로의 Tensor 라는 자료형이고, 상수를 담고 있다는 의미 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#텐서를 이용한 덧셈 연산\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " →  42 라는 결과가 나오지 않는다 !\n",
    "\n",
    " **왜?** 텐서플로는 위에서 말했듯이 2가지 구조로 분리되어 있기 때문이다.\n",
    "\n",
    "텐서와 텐서의 연산들을 먼저 정의하여 그래프를 만들고, 이후 필요할 때 연산을 실행하는 **지연실행** 방식이다.\n",
    "\n",
    "그래프의 실행은 **Session** 안에서 이뤄지며, Session 객체와 run 메서드를 이용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 플레이스홀더와 변수\n",
    "\n",
    "1. 플레이스홀더 : 그래프에 사용할 입력값을 나중에 받기 위해 사용\n",
    "2. 변수 : 그래프 최적화 용도로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#플레이스홀더\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 3]) #None : 크기가 정해지지 않았음 & 자료형, shape 지정\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#나중에 플레이스홀더 X에 넣을 자료 정의\n",
    "\n",
    "x_data = [[1,2,3],[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#변수 정의\n",
    "\n",
    "#random_normal : 정규분포의 무작위 값으로 초기화\n",
    "W = tf.Variable(tf.random_normal([3,2])) #3x2 행렬\n",
    "b = tf.Variable(tf.random_normal([2,1])) #2x1 행렬 \n",
    "\n",
    "#직접 원하는 텐서의 형태의 데이터 만들기\n",
    "W = tf.Variable([[0.1, 0.1], [0.2,0.2], [0.3, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#행렬의 연산\n",
    "\n",
    "expr = tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== x_data ===\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "\n",
      "=== W ===\n",
      "[[0.1 0.1]\n",
      " [0.2 0.2]\n",
      " [0.3 0.3]]\n",
      "\n",
      "=== b ===\n",
      "[[1.7334347 ]\n",
      " [0.32189128]]\n",
      "\n",
      "=== expr ===\n",
      "[[3.1334348 3.1334348]\n",
      " [3.5218914 3.5218914]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) #앞에서 정의한 변수들을 초기화\n",
    "\n",
    "print('=== x_data ===')\n",
    "print(x_data)\n",
    "print('\\n=== W ===')\n",
    "print(sess.run(W))\n",
    "print('\\n=== b ===')\n",
    "print(sess.run(b))\n",
    "print('\\n=== expr ===')\n",
    "print(sess.run(expr, feed_dict={X:x_data})) #feed_dict : 그래프를 실행할 때 사용할 입력값을 지정\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델 구현하기\n",
    "\n",
    "선형회귀 : 주어진 x 와 y 를 가지고 서로 간의 관계를 파악하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#목표 : 주어진 x와 y의 상관관계 파악\n",
    "\n",
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W,b를 각각 -1부터 1사이의 균등분포를 가진 무작위 값으로 초기화\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#자료를 입력받을 플레이스홀더 설정\n",
    "\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관관계 분석을 위한 수식 작성\n",
    "\n",
    "hypothesis = W*X + b #W: 가중치 , b: 편향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수(예측값과 실제값의 차이) 정의\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실값을 최소화하는 연산 그래프 생성 : gradient descent 최적화 함수 이용\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1) #학습률 (얼마나 급하게)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적화 함수**란 가중치(W)와 편향(b)값을 변경해 가면서 손실값을 최소화하는 가장 최적화된 W,b를 찾아주는 함수 !\n",
    "\n",
    "-------------\n",
    "\n",
    "이때 값을 무작위로 변경하면 시간이 너무 오래 걸리기때문에 **gradient descent** 방법을 사용하는데,\n",
    "\n",
    "함수의 기울기를 구하고 기울기가 낮은 쪽으로 이동시키면서 최적의 값을 찾아 나가는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2395592 [0.69759285] [0.8912982]\n",
      "1 0.1430397 [0.6233202] [0.83400136]\n",
      "2 0.10109487 [0.64128745] [0.817873]\n",
      "3 0.09587289 [0.6489366] [0.79778343]\n",
      "4 0.09131387 [0.6574824] [0.7786521]\n",
      "5 0.08697635 [0.66570467] [0.7599287]\n",
      "6 0.08284491 [0.6737422] [0.7416611]\n",
      "7 0.0789097 [0.6815851] [0.723832]\n",
      "8 0.07516145 [0.68923956] [0.70643157]\n",
      "9 0.07159117 [0.69671] [0.6894494]\n",
      "10 0.0681906 [0.70400095] [0.6728756]\n",
      "11 0.06495147 [0.7111165] [0.6567001]\n",
      "12 0.061866213 [0.7180611] [0.6409135]\n",
      "13 0.05892751 [0.7248387] [0.62550634]\n",
      "14 0.056128424 [0.73145336] [0.6104696]\n",
      "15 0.053462297 [0.7379091] [0.5957943]\n",
      "16 0.050922763 [0.7442095] [0.5814718]\n",
      "17 0.04850393 [0.7503586] [0.5674936]\n",
      "18 0.046199944 [0.75635976] [0.5538514]\n",
      "19 0.04400542 [0.76221675] [0.54053724]\n",
      "20 0.041915093 [0.7679329] [0.52754307]\n",
      "21 0.03992411 [0.77351165] [0.5148613]\n",
      "22 0.038027693 [0.77895623] [0.5024844]\n",
      "23 0.036221348 [0.78427] [0.490405]\n",
      "24 0.034500804 [0.789456] [0.478616]\n",
      "25 0.032861974 [0.7945173] [0.4671104]\n",
      "26 0.031301025 [0.799457] [0.45588142]\n",
      "27 0.029814214 [0.8042779] [0.44492233]\n",
      "28 0.028397998 [0.8089829] [0.4342267]\n",
      "29 0.027049065 [0.81357485] [0.4237882]\n",
      "30 0.02576422 [0.81805634] [0.4136006]\n",
      "31 0.024540396 [0.82243013] [0.4036579]\n",
      "32 0.02337472 [0.82669884] [0.39395428]\n",
      "33 0.022264386 [0.8308649] [0.3844839]\n",
      "34 0.021206835 [0.8349308] [0.37524116]\n",
      "35 0.020199483 [0.83889896] [0.36622062]\n",
      "36 0.019239986 [0.84277165] [0.3574169]\n",
      "37 0.01832607 [0.84655136] [0.34882486]\n",
      "38 0.017455583 [0.8502402] [0.34043935]\n",
      "39 0.016626438 [0.8538403] [0.33225542]\n",
      "40 0.01583667 [0.85735387] [0.32426822]\n",
      "41 0.015084393 [0.860783] [0.31647304]\n",
      "42 0.014367891 [0.86412966] [0.30886525]\n",
      "43 0.013685383 [0.8673958] [0.30144033]\n",
      "44 0.013035342 [0.8705836] [0.29419395]\n",
      "45 0.012416136 [0.87369466] [0.2871217]\n",
      "46 0.011826375 [0.8767309] [0.2802195]\n",
      "47 0.011264614 [0.8796942] [0.27348322]\n",
      "48 0.010729536 [0.8825863] [0.26690888]\n",
      "49 0.010219866 [0.8854088] [0.26049256]\n",
      "50 0.0097344285 [0.88816357] [0.25423053]\n",
      "51 0.009272027 [0.89085203] [0.248119]\n",
      "52 0.008831597 [0.89347583] [0.24215436]\n",
      "53 0.008412086 [0.8960366] [0.23633315]\n",
      "54 0.008012511 [0.89853585] [0.23065187]\n",
      "55 0.0076319054 [0.9009749] [0.22510715]\n",
      "56 0.00726939 [0.9033555] [0.21969575]\n",
      "57 0.0069240886 [0.90567875] [0.2144144]\n",
      "58 0.0065951874 [0.90794617] [0.20926003]\n",
      "59 0.0062819156 [0.91015905] [0.20422955]\n",
      "60 0.0059835166 [0.9123188] [0.19932002]\n",
      "61 0.0056992844 [0.91442657] [0.19452848]\n",
      "62 0.005428571 [0.9164837] [0.18985215]\n",
      "63 0.005170709 [0.91849136] [0.18528822]\n",
      "64 0.0049250987 [0.9204508] [0.18083404]\n",
      "65 0.004691151 [0.9223631] [0.1764869]\n",
      "66 0.004468316 [0.92422944] [0.17224427]\n",
      "67 0.0042560664 [0.9260509] [0.16810364]\n",
      "68 0.0040539084 [0.9278286] [0.16406253]\n",
      "69 0.0038613435 [0.9295635] [0.16011856]\n",
      "70 0.0036779258 [0.93125683] [0.15626945]\n",
      "71 0.0035032176 [0.9329093] [0.15251282]\n",
      "72 0.003336817 [0.93452215] [0.14884652]\n",
      "73 0.0031783113 [0.9360962] [0.14526835]\n",
      "74 0.0030273385 [0.9376324] [0.14177619]\n",
      "75 0.0028835398 [0.9391317] [0.13836801]\n",
      "76 0.002746573 [0.940595] [0.13504176]\n",
      "77 0.0026161075 [0.9420229] [0.1317954]\n",
      "78 0.0024918362 [0.94341666] [0.12862715]\n",
      "79 0.0023734756 [0.9447769] [0.12553506]\n",
      "80 0.002260736 [0.94610447] [0.1225173]\n",
      "81 0.0021533465 [0.94740003] [0.11957206]\n",
      "82 0.002051063 [0.9486645] [0.11669763]\n",
      "83 0.0019536354 [0.9498986] [0.11389231]\n",
      "84 0.0018608393 [0.95110303] [0.11115441]\n",
      "85 0.0017724443 [0.95227844] [0.10848232]\n",
      "86 0.0016882485 [0.95342565] [0.10587449]\n",
      "87 0.0016080603 [0.9545452] [0.10332932]\n",
      "88 0.0015316759 [0.95563793] [0.10084537]\n",
      "89 0.001458919 [0.9567044] [0.09842113]\n",
      "90 0.0013896193 [0.9577452] [0.09605516]\n",
      "91 0.0013236079 [0.9587609] [0.09374604]\n",
      "92 0.0012607417 [0.9597523] [0.09149247]\n",
      "93 0.0012008523 [0.9607199] [0.08929306]\n",
      "94 0.0011438123 [0.9616641] [0.08714649]\n",
      "95 0.0010894829 [0.9625857] [0.08505156]\n",
      "96 0.0010377284 [0.9634851] [0.08300698]\n",
      "97 0.0009884408 [0.9643629] [0.08101154]\n",
      "98 0.00094148563 [0.96521956] [0.07906405]\n",
      "99 0.00089676096 [0.96605563] [0.07716341]\n",
      "\n",
      "=== test ===\n",
      "X:5, Y: [4.9074416]\n",
      "X:2.5, Y: [2.4923027]\n"
     ]
    }
   ],
   "source": [
    "#with 기능을 이용해 세션 블록을 만들고 세션 종료를 자동으로 처리하도록 만든다.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        print(step, cost_val, sess.run(W),sess.run(b))\n",
    "    #학습에 사용되지 않았던 값으로 확인해보기\n",
    "    \n",
    "    print('\\n=== test ===')\n",
    "    print('X:5, Y:', sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print('X:2.5, Y:', sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 성공 ~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
