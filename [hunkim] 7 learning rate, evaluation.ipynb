{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "#evaluation our model using this test dataset\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.7444763 [[-0.10079545 -0.4203277  -0.6742114 ]\n",
      " [-0.40040308  0.58891726 -0.654435  ]\n",
      " [-0.06634343 -2.1062694   0.97937703]] \n",
      "\n",
      "1 4.4631276 [[-0.09052564 -0.38931626 -0.7154926 ]\n",
      " [-0.28490943  0.74901587 -0.93002725]\n",
      " [ 0.05968171 -1.9271551   0.6742377 ]] \n",
      "\n",
      "2 2.9361134 [[-0.13479057 -0.3623453  -0.6981986 ]\n",
      " [-0.45658827  0.89523524 -0.9045677 ]\n",
      " [-0.09976079 -1.7574329   0.663958  ]] \n",
      "\n",
      "3 2.2808743 [[-0.13686275 -0.35362372 -0.704848  ]\n",
      " [-0.41478264  0.95122546 -1.0023636 ]\n",
      " [-0.05779784 -1.6545963   0.5191584 ]] \n",
      "\n",
      "4 2.0531294 [[-0.15579604 -0.35331774 -0.6862207 ]\n",
      " [-0.45639876  0.96137714 -0.9708991 ]\n",
      " [-0.11241053 -1.593421    0.51259583]] \n",
      "\n",
      "5 2.0001464 [[-0.16084021 -0.36169934 -0.67279494]\n",
      " [-0.42732593  0.92396617 -0.96256095]\n",
      " [-0.09437963 -1.5768898   0.47803366]] \n",
      "\n",
      "6 1.9647747 [[-0.17218512 -0.36656496 -0.65658444]\n",
      " [-0.4297116   0.9054684  -0.9416775 ]\n",
      " [-0.10918987 -1.5428586   0.4588128 ]] \n",
      "\n",
      "7 1.9334619 [[-0.18079978 -0.37308377 -0.64145094]\n",
      " [-0.41805747  0.87768936 -0.9255526 ]\n",
      " [-0.10940138 -1.5178819   0.4340476 ]] \n",
      "\n",
      "8 1.9030737 [[-0.19077282 -0.3787101  -0.6258516 ]\n",
      " [-0.41308093  0.8545396  -0.9073793 ]\n",
      " [-0.11643863 -1.4888879   0.41209093]] \n",
      "\n",
      "9 1.8731453 [[-0.2001659  -0.38465577 -0.6105128 ]\n",
      " [-0.40497455  0.82939905 -0.89034516]\n",
      " [-0.12015872 -1.462113    0.38903612]] \n",
      "\n",
      "10 1.8435769 [[-0.209905   -0.3903283  -0.5951012 ]\n",
      " [-0.3984448   0.80550975 -0.87298566]\n",
      " [-0.12541094 -1.434523    0.36669832]] \n",
      "\n",
      "11 1.8143536 [[-0.21953495 -0.39602008 -0.57977945]\n",
      " [-0.39119264  0.7812758  -0.85600394]\n",
      " [-0.12982519 -1.4076269   0.3442164 ]] \n",
      "\n",
      "12 1.7854803 [[-0.22927856 -0.40158337 -0.56447256]\n",
      " [-0.38436157  0.7575093  -0.8390685 ]\n",
      " [-0.13457279 -1.3806745   0.32201165]] \n",
      "\n",
      "13 1.756964 [[-0.23902032 -0.40709338 -0.5492208 ]\n",
      " [-0.37737596  0.7338026  -0.8223474 ]\n",
      " [-0.13906032 -1.3540595   0.29988408]] \n",
      "\n",
      "14 1.7288145 [[-0.24881618 -0.41251066 -0.53400767]\n",
      " [-0.37053317  0.7103762  -0.8057638 ]\n",
      " [-0.14358883 -1.3275872   0.27794036]] \n",
      "\n",
      "15 1.7010405 [[-0.2586335  -0.41785595 -0.5188451 ]\n",
      " [-0.36367974  0.68712175 -0.7893628 ]\n",
      " [-0.14799848 -1.3013713   0.2561341 ]] \n",
      "\n",
      "16 1.6736515 [[-0.26848593 -0.42311805 -0.50373054]\n",
      " [-0.3568989   0.6641062  -0.7731281 ]\n",
      " [-0.15237099 -1.2753617   0.23449694]] \n",
      "\n",
      "17 1.646657 [[-0.27836236 -0.42830315 -0.488669  ]\n",
      " [-0.3501476   0.6413018  -0.7570751 ]\n",
      " [-0.15665945 -1.249597    0.21302062]] \n",
      "\n",
      "18 1.6200662 [[-0.28826493 -0.433408   -0.4736616 ]\n",
      " [-0.34345123  0.6187331  -0.7412028 ]\n",
      " [-0.16088651 -1.2240673   0.191718  ]] \n",
      "\n",
      "19 1.5938886 [[-0.29818833 -0.43843475 -0.45871145]\n",
      " [-0.33679745  0.5963955  -0.72551894]\n",
      " [-0.16503651 -1.1987904   0.17059106]] \n",
      "\n",
      "20 1.5681336 [[-0.30813125 -0.44338268 -0.44382057]\n",
      " [-0.33019513  0.57430106 -0.7100268 ]\n",
      " [-0.16911526 -1.1737685   0.14964786]] \n",
      "\n",
      "21 1.5428103 [[-0.31809002 -0.44825286 -0.4289916 ]\n",
      " [-0.3236412   0.5524525  -0.6947322 ]\n",
      " [-0.17311636 -1.1490129   0.12889338]] \n",
      "\n",
      "22 1.5179278 [[-0.32806224 -0.45304546 -0.41422677]\n",
      " [-0.3171395   0.53085816 -0.6796395 ]\n",
      " [-0.17704032 -1.1245301   0.10833451]] \n",
      "\n",
      "23 1.493495 [[-0.33804458 -0.45776135 -0.39952853]\n",
      " [-0.3106899   0.50952315 -0.6647541 ]\n",
      " [-0.18088359 -1.1003295   0.08797727]] \n",
      "\n",
      "24 1.4695203 [[-0.3480342  -0.46240115 -0.3848991 ]\n",
      " [-0.3042949   0.4884548  -0.65008074]\n",
      " [-0.18464509 -1.0764191   0.06782835]] \n",
      "\n",
      "25 1.4460125 [[-0.35802788 -0.4669658  -0.3703408 ]\n",
      " [-0.29795548  0.46765915 -0.6356245 ]\n",
      " [-0.18832205 -1.0528079   0.04789412]] \n",
      "\n",
      "26 1.4229794 [[-0.3680225  -0.4714562  -0.35585576]\n",
      " [-0.29167366  0.4471432  -0.6213904 ]\n",
      " [-0.19191271 -1.0295044   0.02818122]] \n",
      "\n",
      "27 1.4004285 [[-0.37801483 -0.4758735  -0.34144613]\n",
      " [-0.2854511   0.42691347 -0.60738325]\n",
      " [-0.19541466 -1.0065174   0.0086962 ]] \n",
      "\n",
      "28 1.3783674 [[-0.38800165 -0.48021886 -0.327114  ]\n",
      " [-0.2792898   0.40697676 -0.59360784]\n",
      " [-0.19882576 -0.9838557  -0.01055438]] \n",
      "\n",
      "29 1.3568025 [[-0.39797968 -0.48449352 -0.3128613 ]\n",
      " [-0.27319187  0.38734    -0.580069  ]\n",
      " [-0.20214379 -0.961528   -0.02956409]] \n",
      "\n",
      "30 1.3357397 [[-0.4079456  -0.48869893 -0.29868996]\n",
      " [-0.2671594   0.3680099  -0.5667713 ]\n",
      " [-0.20536639 -0.93954295 -0.04832654]] \n",
      "\n",
      "31 1.3151847 [[-0.41789618 -0.49283653 -0.28460178]\n",
      " [-0.2611948   0.3489932  -0.5537193 ]\n",
      " [-0.20849134 -0.9179091  -0.06683548]] \n",
      "\n",
      "32 1.2951424 [[-0.42782813 -0.49690792 -0.27059847]\n",
      " [-0.25530046  0.33029673 -0.54091716]\n",
      " [-0.21151637 -0.89663464 -0.0850849 ]] \n",
      "\n",
      "33 1.2756159 [[-0.43773815 -0.5009147  -0.25668165]\n",
      " [-0.24947886  0.31192696 -0.528369  ]\n",
      " [-0.21443915 -0.8757278  -0.10306898]] \n",
      "\n",
      "34 1.2566092 [[-0.447623   -0.5048586  -0.24285287]\n",
      " [-0.24373272  0.29389048 -0.5160787 ]\n",
      " [-0.21725759 -0.8551961  -0.12078217]] \n",
      "\n",
      "35 1.2381238 [[-0.45747954 -0.50874144 -0.22911353]\n",
      " [-0.2380646   0.27619344 -0.5040498 ]\n",
      " [-0.21996942 -0.8350472  -0.13821927]] \n",
      "\n",
      "36 1.220161 [[-0.4673046  -0.51256496 -0.215465  ]\n",
      " [-0.23247735  0.258842   -0.49228555]\n",
      " [-0.2225727  -0.81528777 -0.15537539]] \n",
      "\n",
      "37 1.2027209 [[-0.47709507 -0.516331   -0.20190847]\n",
      " [-0.22697362  0.24184172 -0.480789  ]\n",
      " [-0.2250654  -0.79592437 -0.17224608]] \n",
      "\n",
      "38 1.1858029 [[-0.48684803 -0.52004147 -0.18844509]\n",
      " [-0.22155628  0.22519809 -0.4695627 ]\n",
      " [-0.2274458  -0.77696276 -0.18882728]] \n",
      "\n",
      "39 1.1694045 [[-0.4965605  -0.52369815 -0.1750759 ]\n",
      " [-0.2162279   0.20891593 -0.45860896]\n",
      " [-0.22971217 -0.7584082  -0.20511547]] \n",
      "\n",
      "40 1.1535226 [[-0.50622976 -0.5273029  -0.16180184]\n",
      " [-0.21099126  0.19299984 -0.4479295 ]\n",
      " [-0.23186319 -0.74026513 -0.22110751]] \n",
      "\n",
      "41 1.1381533 [[-0.5158531  -0.5308576  -0.14862376]\n",
      " [-0.20584883  0.17745365 -0.43752575]\n",
      " [-0.2338975  -0.7225374  -0.23680091]] \n",
      "\n",
      "42 1.1232909 [[-0.525428   -0.53436404 -0.13554241]\n",
      " [-0.20080306  0.16228084 -0.4273987 ]\n",
      " [-0.23581421 -0.7052279  -0.2521937 ]] \n",
      "\n",
      "43 1.1089288 [[-0.53495204 -0.537824   -0.12255844]\n",
      " [-0.19585623  0.14748412 -0.41754884]\n",
      " [-0.23761258 -0.6883389  -0.26728436]] \n",
      "\n",
      "44 1.0950596 [[-0.544423   -0.541239   -0.10967246]\n",
      " [-0.19101039  0.13306563 -0.40797618]\n",
      " [-0.23929209 -0.6718716  -0.28207213]] \n",
      "\n",
      "45 1.0816748 [[-0.5538387  -0.54461086 -0.09688491]\n",
      " [-0.18626742  0.11902669 -0.3986802 ]\n",
      " [-0.24085258 -0.6558267  -0.29655656]] \n",
      "\n",
      "46 1.0687649 [[-0.5631972  -0.54794097 -0.08419625]\n",
      " [-0.18162902  0.10536817 -0.3896601 ]\n",
      " [-0.2422942  -0.6402036  -0.31073803]] \n",
      "\n",
      "47 1.0563192 [[-0.5724968  -0.55123085 -0.07160677]\n",
      " [-0.1770965   0.09208991 -0.38091436]\n",
      " [-0.24361733 -0.62500125 -0.32461727]] \n",
      "\n",
      "48 1.044327 [[-0.5817358  -0.55448186 -0.05911673]\n",
      " [-0.17267103  0.07919127 -0.37244117]\n",
      " [-0.24482265 -0.6102175  -0.33819568]] \n",
      "\n",
      "49 1.0327759 [[-0.59091276 -0.5576953  -0.0467263 ]\n",
      " [-0.16835345  0.06667075 -0.36423823]\n",
      " [-0.24591115 -0.5958496  -0.35147512]] \n",
      "\n",
      "50 1.0216538 [[-0.6000264  -0.56087244 -0.03443556]\n",
      " [-0.16414438  0.05452616 -0.3563027 ]\n",
      " [-0.24688415 -0.5818938  -0.3644579 ]] \n",
      "\n",
      "51 1.0109476 [[-0.60907567 -0.56401426 -0.02224453]\n",
      " [-0.16004404  0.04275459 -0.3486315 ]\n",
      " [-0.2477431  -0.56834584 -0.3771469 ]] \n",
      "\n",
      "52 1.0006437 [[-0.6180595  -0.5671218  -0.01015316]\n",
      " [-0.15605253  0.03135255 -0.34122097]\n",
      " [-0.24848986 -0.5552007  -0.3895453 ]] \n",
      "\n",
      "53 0.9907287 [[-0.62697715 -0.57019603  0.00183867]\n",
      " [-0.15216948  0.0203158  -0.33406729]\n",
      " [-0.24912633 -0.54245275 -0.40165678]] \n",
      "\n",
      "54 0.98118854 [[-0.6358279  -0.5732378   0.01373117]\n",
      " [-0.14839453  0.0096397  -0.32716614]\n",
      " [-0.24965487 -0.53009564 -0.41348532]] \n",
      "\n",
      "55 0.9720092 [[-0.6446113  -0.5762478   0.02552457]\n",
      " [-0.14472671 -0.00068124 -0.320513  ]\n",
      " [-0.25007772 -0.5181228  -0.4250353 ]] \n",
      "\n",
      "56 0.9631768 [[-0.653327   -0.5792268   0.03721922]\n",
      " [-0.14116524 -0.01065264 -0.31410307]\n",
      " [-0.25039768 -0.5065269  -0.43631124]] \n",
      "\n",
      "57 0.9546771 [[-0.66197467 -0.5821754   0.04881548]\n",
      " [-0.1377087  -0.02028095 -0.3079313 ]\n",
      " [-0.25061727 -0.49530044 -0.4473181 ]] \n",
      "\n",
      "58 0.9464965 [[-0.6705543  -0.5850941   0.0603138 ]\n",
      " [-0.13435581 -0.02957268 -0.30199245]\n",
      " [-0.2507395  -0.48443538 -0.45806092]] \n",
      "\n",
      "59 0.93862104 [[-0.6790658  -0.5879834   0.07171467]\n",
      " [-0.13110484 -0.03853496 -0.29628113]\n",
      " [-0.25076723 -0.47392362 -0.468545  ]] \n",
      "\n",
      "60 0.9310378 [[-0.6875094  -0.59084386  0.08301865]\n",
      " [-0.1279541  -0.04717505 -0.29079178]\n",
      " [-0.2507035  -0.46375668 -0.47877568]] \n",
      "\n",
      "61 0.92373335 [[-0.69588524 -0.59367573  0.09422631]\n",
      " [-0.12490162 -0.05550047 -0.28551883]\n",
      " [-0.2505514  -0.4539259  -0.48875856]] \n",
      "\n",
      "62 0.9166951 [[-0.7041936  -0.5964794   0.10533832]\n",
      " [-0.12194539 -0.06351902 -0.2804565 ]\n",
      " [-0.25031406 -0.4444226  -0.4984992 ]] \n",
      "\n",
      "63 0.9099107 [[-0.7124348  -0.5992552   0.11635537]\n",
      " [-0.11908324 -0.07123861 -0.27559906]\n",
      " [-0.24999462 -0.43523794 -0.5080033 ]] \n",
      "\n",
      "64 0.903368 [[-0.7206094  -0.6020034   0.12727818]\n",
      " [-0.11631295 -0.07866722 -0.27094075]\n",
      " [-0.24959624 -0.42636305 -0.5172766 ]] \n",
      "\n",
      "65 0.8970558 [[-0.7287179  -0.6047242   0.13810752]\n",
      " [-0.11363219 -0.08581297 -0.26647577]\n",
      " [-0.24912204 -0.41778907 -0.52632475]] \n",
      "\n",
      "66 0.89096284 [[-0.7367609  -0.60741794  0.1488442 ]\n",
      " [-0.11103857 -0.09268399 -0.2621984 ]\n",
      " [-0.2485751  -0.4095072  -0.53515357]] \n",
      "\n",
      "67 0.8850786 [[-0.744739   -0.6100847   0.15948904]\n",
      " [-0.10852974 -0.09928834 -0.25810286]\n",
      " [-0.24795857 -0.40150857 -0.5437687 ]] \n",
      "\n",
      "68 0.8793929 [[-0.7526529  -0.6127247   0.1700429 ]\n",
      " [-0.10610322 -0.10563418 -0.25418356]\n",
      " [-0.24727543 -0.3937846  -0.5521758 ]] \n",
      "\n",
      "69 0.87389606 [[-0.7605033  -0.6153381   0.18050669]\n",
      " [-0.1037566  -0.11172947 -0.25043488]\n",
      " [-0.24652867 -0.38632667 -0.5603805 ]] \n",
      "\n",
      "70 0.8685788 [[-0.768291   -0.61792505  0.1908813 ]\n",
      " [-0.10148738 -0.11758222 -0.24685134]\n",
      " [-0.24572119 -0.37912634 -0.56838834]] \n",
      "\n",
      "71 0.8634323 [[-0.7760167  -0.62048566  0.20116767]\n",
      " [-0.09929314 -0.12320025 -0.24342754]\n",
      " [-0.2448558  -0.3721753  -0.5762047 ]] \n",
      "\n",
      "72 0.85844827 [[-0.78368133 -0.6230201   0.21136676]\n",
      " [-0.09717147 -0.12859128 -0.24015817]\n",
      " [-0.24393535 -0.36546543 -0.58383507]] \n",
      "\n",
      "73 0.8536186 [[-0.7912857  -0.6255285   0.22147952]\n",
      " [-0.0951199  -0.133763   -0.23703802]\n",
      " [-0.2429624  -0.3589888  -0.59128463]] \n",
      "\n",
      "74 0.8489359 [[-0.7988306  -0.628011    0.23150694]\n",
      " [-0.0931362  -0.13872269 -0.23406202]\n",
      " [-0.24193972 -0.3527375  -0.5985586 ]] \n",
      "\n",
      "75 0.8443929 [[-0.80631703 -0.63046765  0.24145001]\n",
      " [-0.09121785 -0.14347781 -0.23122522]\n",
      " [-0.24086966 -0.34670413 -0.60566205]] \n",
      "\n",
      "76 0.83998305 [[-0.81374574 -0.6328986   0.25130972]\n",
      " [-0.08936273 -0.1480353  -0.22852282]\n",
      " [-0.23975481 -0.34088108 -0.6125999 ]] \n",
      "\n",
      "77 0.83569974 [[-0.82111764 -0.63530403  0.2610871 ]\n",
      " [-0.08756844 -0.15240234 -0.22595008]\n",
      " [-0.23859736 -0.3352614  -0.619377  ]] \n",
      "\n",
      "78 0.8315369 [[-0.8284337  -0.637684    0.2707831 ]\n",
      " [-0.08583297 -0.15658543 -0.22350246]\n",
      " [-0.23739977 -0.32983786 -0.62599814]] \n",
      "\n",
      "79 0.82748914 [[-0.83569473 -0.6400386   0.28039876]\n",
      " [-0.08415394 -0.16059141 -0.2211755 ]\n",
      " [-0.23616396 -0.3246039  -0.6324679 ]] \n",
      "\n",
      "80 0.8235506 [[-0.84290165 -0.642368    0.2899351 ]\n",
      " [-0.08252955 -0.16442642 -0.2189649 ]\n",
      " [-0.23489232 -0.31955266 -0.6387908 ]] \n",
      "\n",
      "81 0.81971645 [[-0.85005534 -0.64467233  0.29939315]\n",
      " [-0.0809575  -0.1680969  -0.21686648]\n",
      " [-0.23358658 -0.31467804 -0.64497113]] \n",
      "\n",
      "82 0.81598186 [[-0.8571567  -0.6469517   0.30877388]\n",
      " [-0.07943601 -0.17160866 -0.21487619]\n",
      " [-0.23224886 -0.30997363 -0.65101326]] \n",
      "\n",
      "83 0.8123423 [[-0.8642066  -0.6492062   0.3180783 ]\n",
      " [-0.07796303 -0.17496772 -0.21299009]\n",
      " [-0.23088086 -0.3054336  -0.65692127]] \n",
      "\n",
      "84 0.80879325 [[-0.871206   -0.65143603  0.32730746]\n",
      " [-0.07653683 -0.17817962 -0.21120441]\n",
      " [-0.22948445 -0.30105206 -0.6626992 ]] \n",
      "\n",
      "85 0.8053309 [[-0.87815565 -0.6536413   0.33646232]\n",
      " [-0.07515553 -0.18124989 -0.20951544]\n",
      " [-0.22806126 -0.2968235  -0.668351  ]] \n",
      "\n",
      "86 0.8019513 [[-0.88505644 -0.65582204  0.3455439 ]\n",
      " [-0.07381746 -0.18418375 -0.20791966]\n",
      " [-0.22661294 -0.29274243 -0.6738804 ]] \n",
      "\n",
      "87 0.7986509 [[-0.8919092  -0.65797853  0.35455313]\n",
      " [-0.07252089 -0.18698637 -0.20641361]\n",
      " [-0.22514096 -0.28880367 -0.6792911 ]] \n",
      "\n",
      "88 0.7954263 [[-0.8987148  -0.66011083  0.36349103]\n",
      " [-0.07126426 -0.18966264 -0.204994  ]\n",
      " [-0.22364686 -0.28500214 -0.68458676]] \n",
      "\n",
      "89 0.79227424 [[-0.905474   -0.6622191   0.37235856]\n",
      " [-0.0700459  -0.1922174  -0.20365757]\n",
      " [-0.22213195 -0.28133306 -0.68977076]] \n",
      "\n",
      "90 0.7891916 [[-0.91218776 -0.6643035   0.38115668]\n",
      " [-0.06886446 -0.19465512 -0.2024013 ]\n",
      " [-0.22059767 -0.2777916  -0.6948465 ]] \n",
      "\n",
      "91 0.7861757 [[-0.91885674 -0.66636413  0.38988635]\n",
      " [-0.06771837 -0.19698037 -0.20122214]\n",
      " [-0.21904519 -0.27437332 -0.69981724]] \n",
      "\n",
      "92 0.7832236 [[-0.9254818  -0.66840124  0.39854848]\n",
      " [-0.06660631 -0.19919732 -0.20011723]\n",
      " [-0.21747579 -0.2710738  -0.70468616]] \n",
      "\n",
      "93 0.78033286 [[-0.93206364 -0.6704149   0.407144  ]\n",
      " [-0.0655269  -0.2013102  -0.19908378]\n",
      " [-0.21589056 -0.26788887 -0.7094563 ]] \n",
      "\n",
      "94 0.777501 [[-0.9386031  -0.6724053   0.41567385]\n",
      " [-0.0644789  -0.20332289 -0.19811909]\n",
      " [-0.21429066 -0.2648144  -0.7141307 ]] \n",
      "\n",
      "95 0.7747258 [[-0.94510084 -0.6743726   0.4241389 ]\n",
      " [-0.06346095 -0.20523934 -0.19722058]\n",
      " [-0.21267702 -0.26184657 -0.71871215]] \n",
      "\n",
      "96 0.7720051 [[-0.9515577  -0.6763169   0.43254006]\n",
      " [-0.062472   -0.20706311 -0.19638576]\n",
      " [-0.21105076 -0.25898147 -0.7232035 ]] \n",
      "\n",
      "97 0.7693366 [[-0.9579743  -0.67823845  0.4408782 ]\n",
      " [-0.0615108  -0.20879786 -0.19561222]\n",
      " [-0.20941271 -0.25621557 -0.7276074 ]] \n",
      "\n",
      "98 0.7667185 [[-0.9643514  -0.68013734  0.44915423]\n",
      " [-0.06057634 -0.21044694 -0.19489759]\n",
      " [-0.20776385 -0.25354528 -0.73192656]] \n",
      "\n",
      "99 0.76414907 [[-0.9706897  -0.6820138   0.45736897]\n",
      " [-0.05966749 -0.21201372 -0.19423968]\n",
      " [-0.20610493 -0.25096732 -0.73616344]] \n",
      "\n",
      "100 0.76162636 [[-0.97698987 -0.683868    0.46552327]\n",
      " [-0.05878327 -0.21350133 -0.19363627]\n",
      " [-0.20443682 -0.24847834 -0.7403205 ]] \n",
      "\n",
      "101 0.7591488 [[-0.9832525  -0.6857      0.47361794]\n",
      " [-0.05792271 -0.21491283 -0.19308533]\n",
      " [-0.20276026 -0.2460752  -0.7444002 ]] \n",
      "\n",
      "102 0.7567148 [[-0.98947835 -0.6875101   0.48165384]\n",
      " [-0.05708485 -0.21625122 -0.19258478]\n",
      " [-0.20107597 -0.24375495 -0.74840474]] \n",
      "\n",
      "103 0.7543229 [[-0.99566793 -0.6892984   0.48963174]\n",
      " [-0.05626885 -0.21751927 -0.19213274]\n",
      " [-0.19938464 -0.2415146  -0.7523364 ]] \n",
      "\n",
      "104 0.75197154 [[-1.001822   -0.6910651   0.49755245]\n",
      " [-0.05547379 -0.21871975 -0.19172733]\n",
      " [-0.1976869  -0.23935138 -0.75619733]] \n",
      "\n",
      "105 0.74965954 [[-1.007941   -0.6928103   0.50541675]\n",
      " [-0.05469889 -0.21985526 -0.19136672]\n",
      " [-0.19598337 -0.23726256 -0.7599897 ]] \n",
      "\n",
      "106 0.7473855 [[-1.0140257  -0.6945343   0.51322544]\n",
      " [-0.05394335 -0.22092836 -0.19104914]\n",
      " [-0.19427463 -0.23524557 -0.7637154 ]] \n",
      "\n",
      "107 0.7451482 [[-1.0200766  -0.6962372   0.5209792 ]\n",
      " [-0.05320642 -0.22194146 -0.19077297]\n",
      " [-0.19256125 -0.23329787 -0.7673765 ]] \n",
      "\n",
      "108 0.74294645 [[-1.0260943  -0.6979192   0.5286789 ]\n",
      " [-0.05248732 -0.22289693 -0.19053657]\n",
      " [-0.19084367 -0.23141707 -0.7709748 ]] \n",
      "\n",
      "109 0.74077916 [[-1.0320793  -0.69958043  0.53632516]\n",
      " [-0.05178549 -0.22379695 -0.19033839]\n",
      " [-0.18912253 -0.22960076 -0.7745123 ]] \n",
      "\n",
      "110 0.7386453 [[-1.0380322  -0.7012211   0.5439187 ]\n",
      " [-0.05110013 -0.2246438  -0.1901769 ]\n",
      " [-0.18739815 -0.2278468  -0.77799064]] \n",
      "\n",
      "111 0.7365439 [[-1.0439534  -0.7028414   0.5514603 ]\n",
      " [-0.05043067 -0.22543949 -0.19005066]\n",
      " [-0.18567103 -0.22615297 -0.7814116 ]] \n",
      "\n",
      "112 0.73447376 [[-1.0498437  -0.7044414   0.5589506 ]\n",
      " [-0.04977651 -0.22618604 -0.18995827]\n",
      " [-0.1839416  -0.22451715 -0.7847768 ]] \n",
      "\n",
      "113 0.7324343 [[-1.0557034  -0.7060214   0.5663903 ]\n",
      " [-0.04913701 -0.22688542 -0.1898984 ]\n",
      " [-0.18221019 -0.2229374  -0.78808796]] \n",
      "\n",
      "114 0.7304244 [[-1.0615331  -0.7075816   0.57378006]\n",
      " [-0.04851169 -0.22753942 -0.18986972]\n",
      " [-0.18047726 -0.2214117  -0.7913466 ]] \n",
      "\n",
      "115 0.7284432 [[-1.0673331  -0.70912206  0.58112055]\n",
      " [-0.04789991 -0.22814995 -0.18987095]\n",
      " [-0.17874303 -0.21993831 -0.79455423]] \n",
      "\n",
      "116 0.72649 [[-1.073104   -0.710643    0.58841246]\n",
      " [-0.0473013  -0.2287186  -0.18990092]\n",
      " [-0.17700797 -0.21851526 -0.7977123 ]] \n",
      "\n",
      "117 0.72456396 [[-1.0788463  -0.7121446   0.5956564 ]\n",
      " [-0.04671524 -0.22924712 -0.18995845]\n",
      " [-0.17527229 -0.21714096 -0.8008223 ]] \n",
      "\n",
      "118 0.7226645 [[-1.0845605  -0.71362704  0.602853  ]\n",
      " [-0.04614135 -0.22973706 -0.1900424 ]\n",
      " [-0.17353633 -0.21581367 -0.8038856 ]] \n",
      "\n",
      "119 0.7207906 [[-1.0902469  -0.71509045  0.6100029 ]\n",
      " [-0.04557911 -0.23018998 -0.19015172]\n",
      " [-0.17180033 -0.2145318  -0.8069034 ]] \n",
      "\n",
      "120 0.7189419 [[-1.095906   -0.71653503  0.6171066 ]\n",
      " [-0.04502813 -0.23060735 -0.19028534]\n",
      " [-0.17006457 -0.21329378 -0.8098772 ]] \n",
      "\n",
      "121 0.71711755 [[-1.1015383  -0.71796095  0.6241648 ]\n",
      " [-0.04448801 -0.23099057 -0.19044223]\n",
      " [-0.1683293  -0.2120981  -0.81280816]] \n",
      "\n",
      "122 0.715317 [[-1.1071441  -0.7193684   0.6311781 ]\n",
      " [-0.04395834 -0.23134105 -0.19062142]\n",
      " [-0.16659473 -0.21094337 -0.8156975 ]] \n",
      "\n",
      "123 0.7135396 [[-1.1127238  -0.72075754  0.638147  ]\n",
      " [-0.04343871 -0.23166011 -0.19082198]\n",
      " [-0.16486104 -0.20982818 -0.81854635]] \n",
      "\n",
      "124 0.71178484 [[-1.1182779  -0.72212857  0.6450721 ]\n",
      " [-0.04292884 -0.23194894 -0.19104299]\n",
      " [-0.16312851 -0.20875113 -0.82135594]] \n",
      "\n",
      "125 0.710052 [[-1.1238067  -0.72348166  0.651954  ]\n",
      " [-0.0424283  -0.2322089  -0.19128358]\n",
      " [-0.16139723 -0.20771101 -0.8241273 ]] \n",
      "\n",
      "126 0.7083409 [[-1.1293107  -0.7248169   0.6587932 ]\n",
      " [-0.04193687 -0.232441   -0.19154292]\n",
      " [-0.1596675  -0.20670646 -0.82686156]] \n",
      "\n",
      "127 0.7066506 [[-1.1347902  -0.72613454  0.6655903 ]\n",
      " [-0.04145409 -0.23264651 -0.19182019]\n",
      " [-0.15793934 -0.20573643 -0.82955974]] \n",
      "\n",
      "128 0.7049809 [[-1.1402454  -0.7274347   0.67234576]\n",
      " [-0.04097979 -0.2328264  -0.19211459]\n",
      " [-0.15621306 -0.2047996  -0.8322229 ]] \n",
      "\n",
      "129 0.7033311 [[-1.145677   -0.72871757  0.6790601 ]\n",
      " [-0.04051358 -0.23298185 -0.19242536]\n",
      " [-0.15448865 -0.20389502 -0.83485186]] \n",
      "\n",
      "130 0.7017009 [[-1.151085   -0.72998327  0.68573385]\n",
      " [-0.04005528 -0.2331137  -0.19275178]\n",
      " [-0.15276638 -0.20302144 -0.8374477 ]] \n",
      "\n",
      "131 0.70008993 [[-1.15647    -0.73123205  0.69236755]\n",
      " [-0.03960452 -0.2332231  -0.19309314]\n",
      " [-0.15104623 -0.20217796 -0.8400113 ]] \n",
      "\n",
      "132 0.69849753 [[-1.1618321  -0.73246396  0.6989617 ]\n",
      " [-0.03916115 -0.23331083 -0.19344877]\n",
      " [-0.14932844 -0.20136346 -0.8425436 ]] \n",
      "\n",
      "133 0.69692343 [[-1.1671718  -0.73367923  0.7055167 ]\n",
      " [-0.03872487 -0.2333779  -0.19381797]\n",
      " [-0.14761308 -0.20057705 -0.8450454 ]] \n",
      "\n",
      "134 0.6953672 [[-1.1724894  -0.73487806  0.7120331 ]\n",
      " [-0.03829545 -0.23342516 -0.19420014]\n",
      " [-0.14590022 -0.1998178  -0.8475175 ]] \n",
      "\n",
      "135 0.6938284 [[-1.1777852  -0.73606056  0.71851134]\n",
      " [-0.03787271 -0.23345335 -0.19459468]\n",
      " [-0.14419001 -0.19908474 -0.84996074]] \n",
      "\n",
      "136 0.69230676 [[-1.1830593  -0.73722684  0.72495186]\n",
      " [-0.03745636 -0.23346336 -0.195001  ]\n",
      " [-0.14248244 -0.19837707 -0.852376  ]] \n",
      "\n",
      "137 0.69080186 [[-1.1883123  -0.73837715  0.7313552 ]\n",
      " [-0.03704629 -0.23345593 -0.19541849]\n",
      " [-0.1407777  -0.1976939  -0.85476387]] \n",
      "\n",
      "138 0.6893133 [[-1.1935444  -0.7395116   0.73772174]\n",
      " [-0.03664224 -0.23343182 -0.19584665]\n",
      " [-0.13907577 -0.19703446 -0.8571252 ]] \n",
      "\n",
      "139 0.6878409 [[-1.1987559  -0.7406304   0.74405193]\n",
      " [-0.03624406 -0.23339173 -0.19628493]\n",
      " [-0.13737677 -0.19639796 -0.8594607 ]] \n",
      "\n",
      "140 0.68638414 [[-1.203947   -0.7417336   0.7503462 ]\n",
      " [-0.03585158 -0.23333631 -0.19673283]\n",
      " [-0.13568076 -0.1957836  -0.86177105]] \n",
      "\n",
      "141 0.68494284 [[-1.2091179  -0.74282146  0.75660497]\n",
      " [-0.03546456 -0.2332663  -0.19718985]\n",
      " [-0.13398774 -0.19519073 -0.86405694]] \n",
      "\n",
      "142 0.6835165 [[-1.214269   -0.74389404  0.7628287 ]\n",
      " [-0.03508295 -0.23318225 -0.1976555 ]\n",
      " [-0.13229786 -0.19461858 -0.86631894]] \n",
      "\n",
      "143 0.6821051 [[-1.2194006  -0.74495155  0.76901776]\n",
      " [-0.03470648 -0.23308487 -0.19812936]\n",
      " [-0.13061103 -0.19406657 -0.86855775]] \n",
      "\n",
      "144 0.6807082 [[-1.2245129  -0.7459941   0.7751726 ]\n",
      " [-0.03433514 -0.2329746  -0.19861096]\n",
      " [-0.12892747 -0.19353388 -0.87077403]] \n",
      "\n",
      "145 0.6793256 [[-1.2296062  -0.74702185  0.7812936 ]\n",
      " [-0.03396857 -0.23285225 -0.19909987]\n",
      " [-0.12724698 -0.19302014 -0.87296826]] \n",
      "\n",
      "146 0.6779569 [[-1.2346805  -0.74803495  0.78738105]\n",
      " [-0.03360694 -0.23271804 -0.1995957 ]\n",
      " [-0.12556987 -0.1925244  -0.8751411 ]] \n",
      "\n",
      "147 0.6766019 [[-1.2397363  -0.74903363  0.7934355 ]\n",
      " [-0.03324978 -0.23257281 -0.20009807]\n",
      " [-0.12389588 -0.1920464  -0.87729305]] \n",
      "\n",
      "148 0.67526025 [[-1.2447737  -0.7500179   0.79945725]\n",
      " [-0.03289729 -0.23241682 -0.20060655]\n",
      " [-0.12222531 -0.19158533 -0.8794247 ]] \n",
      "\n",
      "149 0.67393184 [[-1.249793   -0.75098795  0.8054467 ]\n",
      " [-0.0325491  -0.23225076 -0.20112082]\n",
      " [-0.12055796 -0.19114083 -0.88153654]] \n",
      "\n",
      "150 0.67261636 [[-1.2547945  -0.75194395  0.81140417]\n",
      " [-0.03220528 -0.23207489 -0.20164052]\n",
      " [-0.11889402 -0.19071218 -0.88362914]] \n",
      "\n",
      "151 0.67131364 [[-1.2597783  -0.75288606  0.81733006]\n",
      " [-0.03186554 -0.23188989 -0.20216526]\n",
      " [-0.11723333 -0.1902991  -0.8857029 ]] \n",
      "\n",
      "152 0.6700233 [[-1.2647446  -0.75381434  0.8232247 ]\n",
      " [-0.03152996 -0.23169595 -0.20269477]\n",
      " [-0.1155761  -0.18990083 -0.8877584 ]] \n",
      "\n",
      "153 0.6687453 [[-1.2696937  -0.75472903  0.8290885 ]\n",
      " [-0.03119827 -0.23149371 -0.2032287 ]\n",
      " [-0.11392213 -0.18951714 -0.889796  ]] \n",
      "\n",
      "154 0.6674793 [[-1.2746259  -0.7556302   0.8349218 ]\n",
      " [-0.03087055 -0.23128338 -0.20376675]\n",
      " [-0.11227164 -0.18914738 -0.89181626]] \n",
      "\n",
      "155 0.666225 [[-1.2795411  -0.756518    0.8407248 ]\n",
      " [-0.03054651 -0.23106553 -0.20430863]\n",
      " [-0.11062444 -0.1887913  -0.8938196 ]] \n",
      "\n",
      "156 0.66498244 [[-1.2844398  -0.7573925   0.846498  ]\n",
      " [-0.03022629 -0.23084031 -0.20485407]\n",
      " [-0.10898073 -0.18844825 -0.8958063 ]] \n",
      "\n",
      "157 0.66375136 [[-1.289322   -0.758254    0.8522417 ]\n",
      " [-0.02990956 -0.23060831 -0.20540278]\n",
      " [-0.10734028 -0.18811804 -0.89777696]] \n",
      "\n",
      "158 0.66253126 [[-1.294188   -0.75910246  0.8579562 ]\n",
      " [-0.02959647 -0.23036969 -0.20595449]\n",
      " [-0.10570333 -0.18780008 -0.8997319 ]] \n",
      "\n",
      "159 0.6613223 [[-1.299038   -0.7599381   0.8636418 ]\n",
      " [-0.02928678 -0.23012489 -0.20650898]\n",
      " [-0.10406969 -0.18749413 -0.90167147]] \n",
      "\n",
      "160 0.66012424 [[-1.3038722  -0.760761    0.8692988 ]\n",
      " [-0.0289805  -0.22987415 -0.207066  ]\n",
      " [-0.10243947 -0.18719971 -0.9035961 ]] \n",
      "\n",
      "161 0.65893674 [[-1.3086907  -0.76157135  0.8749276 ]\n",
      " [-0.02867749 -0.22961786 -0.2076253 ]\n",
      " [-0.10081257 -0.18691656 -0.90550613]] \n",
      "\n",
      "162 0.65775967 [[-1.3134936  -0.7623692   0.88052845]\n",
      " [-0.0283778  -0.22935621 -0.20818664]\n",
      " [-0.09918909 -0.18664423 -0.9074019 ]] \n",
      "\n",
      "163 0.65659297 [[-1.3182813  -0.76315475  0.88610166]\n",
      " [-0.02808122 -0.22908959 -0.20874985]\n",
      " [-0.09756891 -0.18638247 -0.9092839 ]] \n",
      "\n",
      "164 0.6554365 [[-1.3230538  -0.7639281   0.8916475 ]\n",
      " [-0.02778781 -0.22881816 -0.20931467]\n",
      " [-0.09595212 -0.1861309  -0.91115224]] \n",
      "\n",
      "165 0.65428984 [[-1.3278114  -0.7646894   0.8971663 ]\n",
      " [-0.02749743 -0.22854228 -0.20988093]\n",
      " [-0.09433863 -0.18588924 -0.9130074 ]] \n",
      "\n",
      "166 0.65315294 [[-1.3325541  -0.7654387   0.90265834]\n",
      " [-0.0272101  -0.22826211 -0.21044843]\n",
      " [-0.0927285  -0.18565714 -0.9148496 ]] \n",
      "\n",
      "167 0.6520258 [[-1.3372822  -0.76617616  0.9081239 ]\n",
      " [-0.02692564 -0.227978   -0.21101698]\n",
      " [-0.09112161 -0.18543442 -0.9166792 ]] \n",
      "\n",
      "168 0.6509081 [[-1.3419957  -0.7669019   0.91356325]\n",
      " [-0.02664416 -0.22769006 -0.21158642]\n",
      " [-0.08951809 -0.18522064 -0.9184965 ]] \n",
      "\n",
      "169 0.64979964 [[-1.346695   -0.7676161   0.91897666]\n",
      " [-0.02636546 -0.22739863 -0.21215655]\n",
      " [-0.08791777 -0.1850157  -0.92030174]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 0.64870054 [[-1.35138    -0.7683188   0.92436445]\n",
      " [-0.02608963 -0.2271038  -0.21272722]\n",
      " [-0.08632079 -0.18481916 -0.92209524]] \n",
      "\n",
      "171 0.6476105 [[-1.356051   -0.7690101   0.92972684]\n",
      " [-0.02581649 -0.2268059  -0.21329828]\n",
      " [-0.084727   -0.18463092 -0.9238773 ]] \n",
      "\n",
      "172 0.6465292 [[-1.3607081  -0.7696902   0.9350641 ]\n",
      " [-0.0255461  -0.226505   -0.21386957]\n",
      " [-0.08313648 -0.18445061 -0.92564815]] \n",
      "\n",
      "173 0.6454567 [[-1.3653516  -0.77035916  0.94037646]\n",
      " [-0.02527833 -0.2262014  -0.21444094]\n",
      " [-0.08154912 -0.18427812 -0.92740804]] \n",
      "\n",
      "174 0.64439285 [[-1.3699814  -0.77101713  0.9456642 ]\n",
      " [-0.02501321 -0.22589521 -0.21501225]\n",
      " [-0.07996498 -0.18411312 -0.9291572 ]] \n",
      "\n",
      "175 0.6433376 [[-1.3745978  -0.7716642   0.9509277 ]\n",
      " [-0.02475067 -0.22558662 -0.21558337]\n",
      " [-0.07838401 -0.1839554  -0.93089586]] \n",
      "\n",
      "176 0.6422906 [[-1.3792008  -0.7723005   0.956167  ]\n",
      " [-0.02449065 -0.22527583 -0.21615417]\n",
      " [-0.07680617 -0.18380478 -0.93262434]] \n",
      "\n",
      "177 0.6412519 [[-1.3837907  -0.77292603  0.96138245]\n",
      " [-0.02423316 -0.22496295 -0.21672453]\n",
      " [-0.07523147 -0.18366103 -0.9343428 ]] \n",
      "\n",
      "178 0.64022124 [[-1.3883675  -0.77354103  0.9665743 ]\n",
      " [-0.02397814 -0.22464819 -0.21729434]\n",
      " [-0.07365988 -0.18352397 -0.9360514 ]] \n",
      "\n",
      "179 0.63919866 [[-1.3929315  -0.77414554  0.9717428 ]\n",
      " [-0.02372557 -0.22433165 -0.21786346]\n",
      " [-0.0720914  -0.18339337 -0.9377505 ]] \n",
      "\n",
      "180 0.63818395 [[-1.3974826  -0.77473974  0.9768881 ]\n",
      " [-0.02347536 -0.22401352 -0.21843179]\n",
      " [-0.07052594 -0.18326911 -0.93944025]] \n",
      "\n",
      "181 0.63717693 [[-1.4020212  -0.7753237   0.98201054]\n",
      " [-0.02322756 -0.22369389 -0.21899922]\n",
      " [-0.06896356 -0.18315095 -0.9411208 ]] \n",
      "\n",
      "182 0.63617766 [[-1.4065472  -0.77589744  0.9871103 ]\n",
      " [-0.02298211 -0.22337289 -0.21956567]\n",
      " [-0.06740422 -0.18303871 -0.9427924 ]] \n",
      "\n",
      "183 0.63518584 [[-1.4110608  -0.7764612   0.9921876 ]\n",
      " [-0.02273892 -0.2230507  -0.22013104]\n",
      " [-0.06584783 -0.18293229 -0.9444552 ]] \n",
      "\n",
      "184 0.63420147 [[-1.4155622  -0.777015    0.9972427 ]\n",
      " [-0.02249807 -0.22272736 -0.22069524]\n",
      " [-0.06429446 -0.18283144 -0.9461094 ]] \n",
      "\n",
      "185 0.6332245 [[-1.4200512  -0.7775589   1.0022757 ]\n",
      " [-0.02225944 -0.22240305 -0.22125818]\n",
      " [-0.06274404 -0.18273605 -0.9477552 ]] \n",
      "\n",
      "186 0.6322547 [[-1.4245282  -0.7780931   1.007287  ]\n",
      " [-0.02202307 -0.22207785 -0.22181976]\n",
      " [-0.06119655 -0.18264596 -0.9493928 ]] \n",
      "\n",
      "187 0.631292 [[-1.4289933  -0.7786176   1.0122768 ]\n",
      " [-0.02178888 -0.22175187 -0.22237991]\n",
      " [-0.05965197 -0.18256103 -0.9510223 ]] \n",
      "\n",
      "188 0.6303363 [[-1.4334466  -0.7791326   1.017245  ]\n",
      " [-0.02155688 -0.22142524 -0.22293855]\n",
      " [-0.0581103  -0.1824811  -0.95264393]] \n",
      "\n",
      "189 0.62938756 [[-1.4378883  -0.7796382   1.0221922 ]\n",
      " [-0.02132702 -0.22109802 -0.22349563]\n",
      " [-0.05657148 -0.18240604 -0.9542578 ]] \n",
      "\n",
      "190 0.6284456 [[-1.4423183  -0.7801344   1.0271184 ]\n",
      " [-0.02109933 -0.22077028 -0.22405106]\n",
      " [-0.05503554 -0.18233569 -0.9558641 ]] \n",
      "\n",
      "191 0.6275104 [[-1.4467368  -0.78062135  1.0320239 ]\n",
      " [-0.02087368 -0.22044222 -0.22460477]\n",
      " [-0.05350237 -0.18227002 -0.9574629 ]] \n",
      "\n",
      "192 0.6265818 [[-1.451144   -0.78109914  1.0369089 ]\n",
      " [-0.02065018 -0.2201138  -0.2251567 ]\n",
      " [-0.05197205 -0.18220878 -0.95905447]] \n",
      "\n",
      "193 0.6256597 [[-1.4555398  -0.7815679   1.0417734 ]\n",
      " [-0.02042869 -0.21978517 -0.2257068 ]\n",
      " [-0.05044445 -0.18215193 -0.9606389 ]] \n",
      "\n",
      "194 0.62474406 [[-1.4599245  -0.7820276   1.0466179 ]\n",
      " [-0.02020929 -0.21945636 -0.226255  ]\n",
      " [-0.04891966 -0.18209928 -0.9622163 ]] \n",
      "\n",
      "195 0.6238348 [[-1.464298   -0.78247845  1.0514423 ]\n",
      " [-0.01999189 -0.21912752 -0.22680125]\n",
      " [-0.04739758 -0.18205081 -0.96378684]] \n",
      "\n",
      "196 0.62293184 [[-1.4686606  -0.7829205   1.0562469 ]\n",
      " [-0.0197765  -0.21879865 -0.2273455 ]\n",
      " [-0.04587823 -0.18200633 -0.9653506 ]] \n",
      "\n",
      "197 0.6220351 [[-1.4730123  -0.7833538   1.0610319 ]\n",
      " [-0.01956308 -0.21846986 -0.22788769]\n",
      " [-0.04436154 -0.18196578 -0.96690786]] \n",
      "\n",
      "198 0.6211444 [[-1.4773533  -0.7837785   1.0657976 ]\n",
      " [-0.01935166 -0.21814118 -0.22842778]\n",
      " [-0.04284757 -0.18192904 -0.9684586 ]] \n",
      "\n",
      "199 0.62025976 [[-1.4816836  -0.78419465  1.070544  ]\n",
      " [-0.01914213 -0.21781275 -0.22896573]\n",
      " [-0.04133619 -0.18189606 -0.97000295]] \n",
      "\n",
      "200 0.61938107 [[-1.4860033  -0.78460234  1.0752714 ]\n",
      " [-0.0189346  -0.21748449 -0.2295015 ]\n",
      " [-0.03982749 -0.18186662 -0.97154105]] \n",
      "\n",
      "Prediction: [2 2 2]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None,3])\n",
    "Y = tf.placeholder('float', [None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "#correct prediction test model\n",
    "prediction = tf.arg_max(hypothesis,1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "#launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initialize tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X: x_data, Y:y_data})\n",
    "        print(step, cost_val, W_val,'\\n')\n",
    "    \n",
    "    #predict\n",
    "    print('Prediction:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "    #caculate the accuracy\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate : NaN\n",
    "\n",
    "1. large learning rate : overshooting\n",
    "2. small learning rate : many iterations until convergence and trapping in local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.605617 [[ 1.210855    0.17893243  0.7891227 ]\n",
      " [ 3.1748695  -3.2512991   1.2147204 ]\n",
      " [ 1.5715561  -3.6485271   1.2037753 ]] \n",
      "\n",
      "20 23.220043 [[ 0.08882427  0.7414324   1.3486533 ]\n",
      " [-0.94387245 -0.62629914  2.7084627 ]\n",
      " [-2.5479536  -0.83602715  2.5107849 ]] \n",
      "\n",
      "40 26.841227 [[ 0.4638242   1.3039172   0.41116858]\n",
      " [ 1.4936275   1.9986703  -2.3540068 ]\n",
      " [-0.11045361  1.9764576  -2.7391999 ]] \n",
      "\n",
      "60 15.082949 [[ 0.8386834   0.36655796  0.9736686 ]\n",
      " [ 3.9308362  -1.9385383  -0.85400677]\n",
      " [ 2.3268952  -1.7733915  -1.4266999 ]] \n",
      "\n",
      "80 25.09394 [[-0.28631562  0.92905784  1.5361677 ]\n",
      " [-0.19416189  0.6864612   0.64599156]\n",
      " [-1.7981038   1.0391085  -0.11420071]] \n",
      "\n",
      "100 8.571569 [[ 0.08867216  0.02789086  2.062347  ]\n",
      " [ 2.2433133  -3.1663625   2.0613403 ]\n",
      " [ 0.6393838  -2.659435    1.1468552 ]] \n",
      "\n",
      "120 18.819302 [[ 0.45899484  0.59039086  1.1295242 ]\n",
      " [ 4.6642404  -0.5413625  -2.9845867 ]\n",
      " [ 3.0630286   0.15306497 -4.0892897 ]] \n",
      "\n",
      "140 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "160 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "180 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "200 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "Prediction: [0 0 0]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#learning_rate 를 1.5로 한 경우\n",
    "\n",
    "X = tf.placeholder('float', [None,3])\n",
    "Y = tf.placeholder('float', [None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.5).minimize(cost)\n",
    "\n",
    "#correct prediction test model\n",
    "prediction = tf.arg_max(hypothesis,1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "#launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initialize tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        if step%20 ==0:\n",
    "            cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X: x_data, Y:y_data})\n",
    "            print(step, cost_val, W_val,'\\n')\n",
    "     \n",
    "    #predict\n",
    "    print('Prediction:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "    #caculate the accuracy\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-normalized inputs : NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.23, 1098100, 809.780029, 813.669983],\n",
    "              [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  7604855600000.0 \n",
      "Prediction:\n",
      " [[-1944427.9]\n",
      " [-3915171.8]\n",
      " [-3079753.2]\n",
      " [-2158651. ]\n",
      " [-2544227. ]\n",
      " [-2565647.8]\n",
      " [-2351444.8]\n",
      " [-2994077.8]]\n",
      "10 Cost:  8.355308e+27 \n",
      "Prediction:\n",
      " [[6.4478146e+13]\n",
      " [1.2980112e+14]\n",
      " [1.0210986e+14]\n",
      " [7.1578465e+13]\n",
      " [8.4359046e+13]\n",
      " [8.5069083e+13]\n",
      " [7.7968756e+13]\n",
      " [9.9269730e+13]]\n",
      "20 Cost:  inf \n",
      "Prediction:\n",
      " [[-2.1372154e+21]\n",
      " [-4.3024337e+21]\n",
      " [-3.3845694e+21]\n",
      " [-2.3725652e+21]\n",
      " [-2.7961949e+21]\n",
      " [-2.8197299e+21]\n",
      " [-2.5843797e+21]\n",
      " [-3.2904292e+21]]\n",
      "30 Cost:  inf \n",
      "Prediction:\n",
      " [[7.0840885e+28]\n",
      " [1.4260997e+29]\n",
      " [1.1218612e+29]\n",
      " [7.8641871e+28]\n",
      " [9.2683649e+28]\n",
      " [9.3463746e+28]\n",
      " [8.5662755e+28]\n",
      " [1.0906572e+29]]\n",
      "40 Cost:  inf \n",
      "Prediction:\n",
      " [[-2.3481166e+36]\n",
      " [-4.7269994e+36]\n",
      " [-3.7185599e+36]\n",
      " [-2.6066908e+36]\n",
      " [-3.0721243e+36]\n",
      " [-3.0979818e+36]\n",
      " [-2.8394074e+36]\n",
      " [-3.6151303e+36]]\n",
      "50 Cost:  inf \n",
      "Prediction:\n",
      " [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "60 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "110 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "120 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "130 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "140 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "150 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "160 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "170 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "180 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "190 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "200 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X,W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(201) :\n",
    "    if step%10 == 0:\n",
    "        cost_val, hy_val, _ = sess.run(\n",
    "            [cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, 'Cost: ', cost_val, '\\nPrediction:\\n', hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ normalized inputs => min-max scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True,\n",
      "             feature_range=MinMaxScaler(copy=True,\n",
      "                                        feature_range=MinMaxScaler(copy=True,\n",
      "                                                                   feature_range=MinMaxScaler(copy=True,\n",
      "                                                                                              feature_range=array([[8.28659973e+02, 8.33450012e+02, 9.08100000e+05, 8.28349976e+02,\n",
      "        8.31659973e+02],\n",
      "       [8.23020020e+02, 8.28070007e+02, 1.82810000e+06, 8.21655029e+02,\n",
      "        8.28070007e+02],\n",
      "       [8.19929993e+02, 8.24400024e+02, 1.43810000...\n",
      "       [8.16000000e+02, 8.20958984e+02, 1.00810000e+06, 8.15489990e+02,\n",
      "        8.19239990e+02],\n",
      "       [8.19359985e+02, 8.23000000e+02, 1.18810000e+06, 8.18469971e+02,\n",
      "        8.18979980e+02],\n",
      "       [8.19000000e+02, 8.23000000e+02, 1.19810000e+06, 8.16000000e+02,\n",
      "        8.20450012e+02],\n",
      "       [8.11700012e+02, 8.15230000e+02, 1.09810000e+06, 8.09780029e+02,\n",
      "        8.13669983e+02],\n",
      "       [8.09510010e+02, 8.16659973e+02, 1.39810000e+06, 8.04539978e+02,\n",
      "        8.09559998e+02]])))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "xy = MinMaxScaler(xy)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
